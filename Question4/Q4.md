### 1. An agent that senses only partial information about the state cannot be perfectly rational.
** False **

A rational agent maximizes its expected performance given the available information.
Even with partial observability, an agent can still be rational if it makes the best possible decision given its knowledge.
Example: A poker-playing AI does not know opponents' cards but can still play optimally by using probability and strategy.
2. There exist task environments in which no pure reflex agent can behave rationally.
True

Pure reflex agents act based only on the current percept without considering history or future consequences.
In complex environments requiring memory or planning, pure reflex agents fail to act rationally.
Example: A self-driving car using only reflex-based reactions (e.g., "stop if object ahead") would struggle with navigation, as it needs to plan routes and anticipate future scenarios.
3. There exists a task environment in which every agent is rational.
False

A task environment can be complex enough that some agents perform suboptimally while others behave rationally.
Counterexample: In chess, a random-moving agent is not rational, while a Minimax-based agent is. Not all agents are rational in this task environment.
4. The input to an agent program is the same as the input to the agent function.
False

The agent function is an abstract mathematical mapping from percept sequences to actions.
The agent program is a concrete implementation (e.g., software code) that runs on a machine.
Example: A chess-playing AI’s function maps board states to moves, but its program takes sensor inputs (e.g., an image of a chessboard) and processes them into a structured format.
5. Every agent function is implementable by some program/machine combination.
False

The number of possible agent functions is uncountably infinite, while programs are countably infinite.
Some functions may require infinite memory or computation, making them non-implementable.
Example: A function that requires an exact solution to an undecidable problem (e.g., the Halting Problem) is not implementable.
6. Suppose an agent selects its action uniformly at random from the set of possible actions. There exists a deterministic task environment in which this agent is rational.
True

If the environment’s optimal action is random, a randomly acting agent may be rational.
Example: In a game where the best strategy is to randomize actions (e.g., Rock-Paper-Scissors against a predictable opponent), a random agent can be rational.
7. It is possible for a given agent to be perfectly rational in two distinct task environments.
True

If the environments require the same optimal decision-making approach, an agent can be rational in both.
Example: A sorting algorithm that follows an optimal approach (e.g., Quicksort) remains rational across different datasets, as long as efficiency is the goal in both cases.
